import os
import sqlite3
import threading

import gradio as gr
from dotenv import load_dotenv
from langchain.document_loaders import TextLoader

from RAG.analyze_conversation_history import analyze_conversation_history
from rag_demo import load_and_split_document, create_vector_store, setup_rag_chain, execute_query

# ç¯å¢ƒè®¾ç½®
load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡
QUESTION_LANG = os.getenv("QUESTION_LANG")  # ä»ç¯å¢ƒå˜é‡è·å– QUESTION_LANG
assert QUESTION_LANG in ['cn', 'en'], QUESTION_LANG

if QUESTION_LANG == "cn":
    title = "ZeroPal"
    title_markdown = """
    <div align="center">
        <img src="https://raw.githubusercontent.com/puyuan1996/RAG/main/assets/banner.svg" width="80%" height="20%" alt="Banner Image">
    </div>
    
    ğŸ“¢ **æ“ä½œè¯´æ˜**ï¼šè¯·åœ¨ä¸‹æ–¹çš„â€œé—®é¢˜â€æ¡†ä¸­è¾“å…¥å…³äº LightZero çš„é—®é¢˜ï¼Œå¹¶ç‚¹å‡»â€œæäº¤â€æŒ‰é’®ã€‚å³ä¾§çš„â€œå›ç­”â€æ¡†å°†å±•ç¤º RAG æ¨¡å‹æä¾›çš„ç­”æ¡ˆã€‚
    æ‚¨å¯ä»¥åœ¨é—®ç­”æ¡†ä¸‹æ–¹æŸ¥çœ‹å½“å‰â€œå¯¹è¯å†å²â€ï¼Œç‚¹å‡»â€œæ¸…é™¤ä¸Šä¸‹æ–‡â€æŒ‰é’®å¯æ¸…ç©ºå†å²è®°å½•ã€‚åœ¨â€œå¯¹è¯å†å²â€æ¡†ä¸‹æ–¹ï¼Œæ‚¨å°†æ‰¾åˆ°ç›¸å…³å‚è€ƒæ–‡æ¡£ï¼Œå…¶ä¸­ç›¸å…³æ–‡æ®µå°†ä»¥é»„è‰²é«˜äº®æ˜¾ç¤ºã€‚
    å¦‚æœæ‚¨å–œæ¬¢è¿™ä¸ªé¡¹ç›®ï¼Œè¯·åœ¨ GitHub [LightZero RAG Demo](https://github.com/puyuan1996/RAG) ä¸Šç»™æˆ‘ä»¬ç‚¹èµï¼âœ¨ æ‚¨çš„æ”¯æŒæ˜¯æˆ‘ä»¬æŒç»­æ›´æ–°çš„åŠ¨åŠ›ã€‚
    
    <div align="center">
        <strong>æ³¨æ„ï¼šç®—æ³•æ¨¡å‹è¾“å‡ºå¯èƒ½åŒ…å«ä¸€å®šçš„éšæœºæ€§ã€‚ç»“æœä¸ä»£è¡¨å¼€å‘è€…å’Œç›¸å…³ AI æœåŠ¡çš„æ€åº¦å’Œæ„è§ã€‚æœ¬é¡¹ç›®å¼€å‘è€…ä¸å¯¹ç»“æœä½œå‡ºä»»ä½•ä¿è¯ï¼Œä»…ä¾›å‚è€ƒä¹‹ç”¨ã€‚ä½¿ç”¨è¯¥æœåŠ¡å³ä»£è¡¨åŒæ„åæ–‡æ‰€è¿°çš„ä½¿ç”¨æ¡æ¬¾ã€‚</strong>
    </div>
    """
    tos_markdown = """
    ### ä½¿ç”¨æ¡æ¬¾
    
    ä½¿ç”¨æœ¬æœåŠ¡çš„ç©å®¶éœ€åŒæ„ä»¥ä¸‹æ¡æ¬¾ï¼š
    
    - æœ¬æœåŠ¡ä¸ºæ¢ç´¢æ€§ç ”ç©¶çš„é¢„è§ˆç‰ˆï¼Œä»…ä¾›éå•†ä¸šç”¨é€”ã€‚
    - æœåŠ¡ä¸å¾—ç”¨äºä»»ä½•éæ³•ã€æœ‰å®³ã€æš´åŠ›ã€ç§æ—ä¸»ä¹‰æˆ–å…¶ä»–ä»¤äººåæ„Ÿçš„ç›®çš„ã€‚
    - æœåŠ¡æä¾›æœ‰é™çš„å®‰å…¨æªæ–½ï¼Œå¹¶å¯èƒ½ç”Ÿæˆä»¤äººåæ„Ÿçš„å†…å®¹ã€‚
    - å¦‚æœæ‚¨å¯¹æœåŠ¡ä½“éªŒä¸æ»¡ï¼Œè¯·é€šè¿‡ opendilab@pjlab.org.cn ä¸æˆ‘ä»¬è”ç³»ï¼æˆ‘ä»¬æ‰¿è¯ºä¿®å¤é—®é¢˜å¹¶ä¸æ–­æ”¹è¿›é¡¹ç›®ã€‚
    - ä¸ºäº†è·å¾—æœ€ä½³ä½“éªŒï¼Œè¯·ä½¿ç”¨å°å¼ç”µè„‘ï¼Œå› ä¸ºç§»åŠ¨è®¾å¤‡å¯èƒ½ä¼šå½±å“è§†è§‰æ•ˆæœã€‚
    
    **ç‰ˆæƒæ‰€æœ‰ Â© 2024 OpenDILabã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚**
    """

# è·¯å¾„å˜é‡,æ–¹ä¾¿ä¹‹åçš„æ–‡ä»¶ä½¿ç”¨
file_path = './documents/LightZero_README_zh.md'

# åŠ è½½åŸå§‹Markdownæ–‡æ¡£
loader = TextLoader(file_path)
orig_documents = loader.load()

# å­˜å‚¨å¯¹è¯å†å²
conversation_history = {}

# åˆ›å»ºçº¿ç¨‹å±€éƒ¨æ•°æ®å¯¹è±¡
threadLocal = threading.local()


def get_db_connection():
    """
    è¿”å›å½“å‰çº¿ç¨‹çš„æ•°æ®åº“è¿æ¥
    """
    conn = getattr(threadLocal, 'conn', None)
    if conn is None:
        # è¿æ¥åˆ°SQLiteæ•°æ®åº“
        conn = sqlite3.connect('database/conversation_history.db')
        c = conn.cursor()
        # Drop the existing 'history' table if it exists
        # c.execute('DROP TABLE IF EXISTS history')
        # åˆ›å»ºå­˜å‚¨å¯¹è¯å†å²çš„è¡¨
        c.execute('''CREATE TABLE IF NOT EXISTS history
                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                     user_id TEXT NOT NULL,
                     user_input TEXT NOT NULL,
                     assistant_output TEXT NOT NULL,
                     timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
        threadLocal.conn = conn
    return conn


def get_db_cursor():
    """
    è¿”å›å½“å‰çº¿ç¨‹çš„æ•°æ®åº“æ¸¸æ ‡
    """
    conn = get_db_connection()
    c = getattr(threadLocal, 'cursor', None)
    if c is None:
        c = conn.cursor()
        threadLocal.cursor = c
    return c


# ç¨‹åºç»“æŸæ—¶æ¸…ç†æ•°æ®åº“è¿æ¥
def close_db_connection():
    conn = getattr(threadLocal, 'conn', None)
    if conn is not None:
        conn.close()
        setattr(threadLocal, 'conn', None)

    c = getattr(threadLocal, 'cursor', None)
    if c is not None:
        c.close()
        setattr(threadLocal, 'cursor', None)


def rag_answer(question, temperature, k, user_id):
    """
    å¤„ç†ç”¨æˆ·é—®é¢˜å¹¶è¿”å›ç­”æ¡ˆå’Œé«˜äº®æ˜¾ç¤ºçš„ä¸Šä¸‹æ–‡

    :param question: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    :param temperature: ç”Ÿæˆç­”æ¡ˆæ—¶ä½¿ç”¨çš„æ¸©åº¦å‚æ•°
    :param k: æ£€ç´¢åˆ°çš„æ–‡æ¡£å—æ•°é‡
    :param user_id: ç”¨æˆ·ID
    :return: æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆå’Œé«˜äº®æ˜¾ç¤ºä¸Šä¸‹æ–‡çš„Markdownæ–‡æœ¬
    """
    try:
        chunks = load_and_split_document(file_path, chunk_size=5000, chunk_overlap=500)
        retriever = create_vector_store(chunks, model='OpenAI', k=k)
        rag_chain = setup_rag_chain(model_name='kimi', temperature=temperature)

        if user_id not in conversation_history:
            conversation_history[user_id] = []

        conversation_history[user_id].append((f"User[{user_id}]", question))

        history_str = "\n".join([f"{role}: {text}" for role, text in conversation_history[user_id]])

        retrieved_documents, answer = execute_query(retriever, rag_chain, history_str, model_name='kimi',
                                                    temperature=temperature)

        ############################
        # è·å–å½“å‰çº¿ç¨‹çš„æ•°æ®åº“è¿æ¥å’Œæ¸¸æ ‡
        ############################
        conn = get_db_connection()
        c = get_db_cursor()

        # åˆ†æå¯¹è¯å†å²
        # analyze_conversation_history()
        # è·å–æ€»çš„å¯¹è¯è®°å½•æ•°
        c.execute("SELECT COUNT(*) FROM history")
        total_records = c.fetchone()[0]
        print(f"æ€»å¯¹è¯è®°å½•æ•°: {total_records}")

        # å°†é—®é¢˜å’Œå›ç­”å­˜å‚¨åˆ°æ•°æ®åº“
        c.execute("INSERT INTO history (user_id, user_input, assistant_output) VALUES (?, ?, ?)",
                  (user_id, question, answer))
        conn.commit()

        # åœ¨æ–‡æ¡£ä¸­é«˜äº®æ˜¾ç¤ºä¸Šä¸‹æ–‡
        context = [retrieved_documents[i].page_content for i in range(len(retrieved_documents))]
        highlighted_document = orig_documents[0].page_content
        for i in range(len(context)):
            highlighted_document = highlighted_document.replace(context[i], f"<mark>{context[i]}</mark>")

        conversation_history[user_id].append(("Assistant", answer))

        full_history = "\n".join([f"{role}: {text}" for role, text in conversation_history[user_id]])
    except Exception as e:
        print(f"An error occurred: {e}")
        return "å¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯,è¯·ç¨åå†è¯•ã€‚", "", ""
    finally:
        # ä¸å†åœ¨è¿™é‡Œå…³é—­æ¸¸æ ‡å’Œè¿æ¥
        pass

    return answer, highlighted_document, full_history


def clear_context(user_id):
    """
    æ¸…é™¤å¯¹è¯å†å²
    """
    if user_id in conversation_history:
        conversation_history[user_id] = []
    return "", "", ""


if __name__ == "__main__":
    with gr.Blocks(title=title, theme='ParityError/Interstellar') as zero_pal:
        gr.Markdown(title_markdown)

        with gr.Row():
            with gr.Column():
                user_id = gr.Textbox(
                    placeholder="è¯·è¾“å…¥æ‚¨çš„çœŸå®å§“åæˆ–æ˜µç§°ä½œä¸ºç”¨æˆ·ID",
                    label="ç”¨æˆ·ID")
                inputs = gr.Textbox(
                    placeholder="è¯·æ‚¨åœ¨è¿™é‡Œè¾“å…¥ä»»ä½•å…³äº LightZero çš„é—®é¢˜ã€‚",
                    label="é—®é¢˜")
                temperature = gr.Slider(minimum=0.0, maximum=1.0, value=0.01, step=0.01, label="æ¸©åº¦å‚æ•°")
                k = gr.Slider(minimum=1, maximum=10, value=5, step=1, label="æ£€ç´¢åˆ°çš„æ–‡æ¡£å—æ•°é‡")
                with gr.Row():
                    gr_submit = gr.Button('æäº¤')
                    gr_clear = gr.Button('æ¸…é™¤ä¸Šä¸‹æ–‡')

            outputs_answer = gr.Textbox(placeholder="å½“ä½ ç‚¹å‡»æäº¤æŒ‰é’®å,è¿™é‡Œä¼šæ˜¾ç¤º RAG æ¨¡å‹ç»™å‡ºçš„å›ç­”ã€‚",
                                        label="å›ç­”")
        outputs_history = gr.Textbox(label="å¯¹è¯å†å²")
        with gr.Row():
            outputs_context = gr.Markdown(label="å‚è€ƒçš„æ–‡æ¡£(æ£€ç´¢å¾—åˆ°çš„ç›¸å…³æ–‡æ®µç”¨é«˜äº®æ˜¾ç¤º)")
        gr_clear.click(clear_context, inputs=user_id, outputs=[outputs_context, outputs_history])
        gr_submit.click(
            rag_answer,
            inputs=[inputs, temperature, k, user_id],
            outputs=[outputs_answer, outputs_context, outputs_history],
        )
        gr.Markdown(tos_markdown)

    concurrency = int(os.environ.get('CONCURRENCY', os.cpu_count()))
    favicon_path = os.path.join(os.path.dirname(__file__), 'assets', 'avatar.png')
    zero_pal.queue().launch(max_threads=concurrency, favicon_path=favicon_path, share=True)

    # åœ¨åˆé€‚çš„åœ°æ–¹ï¼Œä¾‹å¦‚ç¨‹åºé€€å‡ºæ—¶ï¼Œè°ƒç”¨close_db_connectionå‡½æ•°
    close_db_connection()
